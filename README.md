# Controlling GPT-3 Outputs for Question Answering

One of the problems with LLMs like GPT-3 is that it can be difficult to fact check their responses. In this notebook, I suggest a different way of using GPT-3 that takes advantage of it's impressive contextual understanding, while restricting its output to a developer's predefined list of facts.
